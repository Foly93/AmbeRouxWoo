{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3734932-1377-4ed9-91a8-08de4e142a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass, field\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from natsort import natsorted\n",
    "import fileinput\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41938ca9-64a2-4a65-affb-2c9414d596e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nConventions:\\nVariabelnames:\\n    high-dimensional-arrays:\\n        - each axis is in the variable name\\n        - each axis is separated by an underscore (dimensionality is #underscores+1)\\n        - each axis name's first letter is capitalised and they should be plural (even if dim == 1)\\n        - the axes might be followed by a descriptor for the elememt's content which should be singular\\n        - for variables, underscores are reserved for high-dimensional-arrays with a few exceptions:\\n            * units that would look totally ugly without an underscore between the constant (kB_kcalmolK | kBkcalmolK)\\n        - Examples:\\n            * axis0_axis1_axis2 -> Hamiltonians_CollectiveVariables_Timeseries\\n            * axis0_axis1Property -> Hamiltonians_CVColumnsSamplesize\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Conventions:\n",
    "Variabelnames:\n",
    "    high-dimensional-arrays:\n",
    "        - each axis is in the variable name\n",
    "        - each axis is separated by an underscore (dimensionality is #underscores+1)\n",
    "        - each axis name's first letter is capitalised and they should be plural (even if dim == 1)\n",
    "        - the axes might be followed by a descriptor for the elememt's content which should be singular\n",
    "        - for variables, underscores are reserved for high-dimensional-arrays with a few exceptions:\n",
    "            * units that would look totally ugly without an underscore between the constant (kB_kcalmolK | kBkcalmolK)\n",
    "        - Examples:\n",
    "            * axis0_axis1_axis2 -> Hamiltonians_CollectiveVariables_Timeseries\n",
    "            * axis0_axis1Property -> Hamiltonians_CVColumnsSamplesize\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38911b74-9b60-49e3-8a16-cb734c769371",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileParser(ABC):\n",
    "    def __init__(self, files, CollectiveVariableColumns, subset=0):\n",
    "        self.files: list[str] = files\n",
    "        self.CVColumns: list[int] = CollectiveVariableColumns\n",
    "        self.verbose: bool = False\n",
    "        self.subset: int = (-subset)\n",
    "        self.__post_init__()\n",
    "        \n",
    "    @abstractmethod\n",
    "    def __post_init__(self):\n",
    "        '''initialise subclass attributes'''\n",
    "    \n",
    "    @abstractmethod\n",
    "    def parse_anchors(self) -> np.ndarray:\n",
    "        '''abstract method to obtain force constant and anchor information form simulation output files'''\n",
    "        \n",
    "    @abstractmethod\n",
    "    def parse_force_constants(self) -> np.ndarray:\n",
    "        '''do stuff'''\n",
    "        \n",
    "    @abstractmethod\n",
    "    def parse_collective_variables(self) -> list[np.ndarray]:\n",
    "        '''abstract method to obtain raw data from simulation output''' \n",
    "\n",
    "    def calculateSamplesize(self) -> list[int]:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "class AMBER_PMD_Parser(FileParser):\n",
    "    def __post_init__(self):\n",
    "        self.columnPattern: str = r'anchor\\({}\\)'\n",
    "        self.anchorRegex: re.Pattern = re.compile(r'position = .?\\d*.\\d+,\\s+(.?\\d*.\\d*),\\s+(.?\\d*.\\d+),\\s+.?\\d*.\\d+')\n",
    "        self.forceConstantRegex: re.Pattern = re.compile(r'strength = (\\d*.\\d+),\\s+(\\d*.\\d*)')\n",
    "        ### this one should not be accessible from init try later first solve the samplesizes problem and the initialisation of the decorrelation engine\n",
    "        self.forceConstantCorrectionFactor: float = 0.5\n",
    "\n",
    "    def parse_anchors(self) -> np.ndarray:\n",
    "        def search_anchor_in_line(file,CVcolumn):\n",
    "            self.columnRegex = re.compile(self.columnPattern.format(CVcolumn))\n",
    "            with open(file) as fileContent:\n",
    "                    for line in fileContent:\n",
    "                        match = re.search(self.columnRegex, line)\n",
    "                        if match: \n",
    "                            anchor1, anchor2 = re.search(self.anchorRegex, line).group(1,2)\n",
    "                            assert anchor1 == anchor2, \"It seems, that your minimum is not defined as a point. Only harmonic potentials are implemented\"\n",
    "                            return float(anchor1)\n",
    "        \n",
    "        def loop_through_files_and_columns():\n",
    "            anchors = []\n",
    "            for file in self.files:\n",
    "                anchors.append([search_anchor_in_line(file,CVcolumn) for CVcolumn in self.CVColumns])\n",
    "            return anchors\n",
    "        \n",
    "        anchors = loop_through_files_and_columns()\n",
    "        anchors = np.array(anchors).reshape(-1, len(self.CVColumns))\n",
    "        return(anchors)\n",
    "        \n",
    "    def parse_force_constants(self) -> np.ndarray:\n",
    "        def search_forceConstants_in_line(file,CVcolumn):\n",
    "            self.columnRegex = re.compile(self.columnPattern.format(CVcolumn))\n",
    "            with open(file) as fileContent:\n",
    "                    for line in fileContent:\n",
    "                        match = re.search(self.columnRegex, line)\n",
    "                        if match: \n",
    "                            forceConstant1, forceConstant2 = re.search(self.forceConstantRegex, next(fileContent)).group(1,2)\n",
    "                            assert forceConstant1 == forceConstant2, \"It seems, that the steepness of your potential is asymmetric. Only harmonic potentials are implemented\"\n",
    "                            return float(forceConstant1)\n",
    "        \n",
    "        def loop_through_files_and_columns():\n",
    "            forceConstants = []\n",
    "            for file in self.files:\n",
    "                forceConstants.append([search_forceConstants_in_line(file,CVcolumn) for CVcolumn in self.CVColumns])\n",
    "            return forceConstants\n",
    "            \n",
    "        forceConstants = loop_through_files_and_columns()\n",
    "        forceConstants = np.array(forceConstants).reshape(-1, len(self.CVColumns))\n",
    "        return(forceConstants * self.forceConstantCorrectionFactor)\n",
    "    \n",
    "    \n",
    "    def parse_collective_variables(self) -> list[np.ndarray]:\n",
    "        CollectiveVariablesList = []\n",
    "        for file in (tqdm(self.files) if self.verbose else self.files):\n",
    "            \n",
    "            CollectiveVariablesDF = pd.read_csv(file,delim_whitespace=True,comment='#',header=None,usecols=self.CVColumns)\n",
    "            CollectiveVariablesList.append(CollectiveVariablesDF.values[self.subset:].T)\n",
    "                 \n",
    "        Hamiltonian_CollectiveVariable_Timeseries = np.column_stack((itertools.zip_longest(*CollectiveVariablesList, fillvalue=0)))\n",
    "        Hamiltonian_CollectiveVariable_Timeseries[~np.isfinite(Hamiltonian_CollectiveVariable_Timeseries)] = 0\n",
    "        Hamiltonian_CollectiveVariable_Timeseries = Hamiltonian_CollectiveVariable_Timeseries.reshape(len(self.files), len(self.CVColumns), -1)\n",
    "        return Hamiltonian_CollectiveVariable_Timeseries\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7140117-82cb-47f4-b403-6afaa02059df",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DecorrelationEngine(ABC):\n",
    "    \n",
    "    Hamiltonian_CollectiveVariable_Timeseries: np.ndarray[float]\n",
    "    Hamiltonian_CVColumnsSamplesize: np.ndarray[int]\n",
    "    correlationTime: np.ndarray[float] = field(init=False)\n",
    "    subsampleIndexArray: np.ndarray[int] = field(init=False)\n",
    "        \n",
    "    @abstractmethod\n",
    "    def find_correlation_time() -> np.ndarray[float]:\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def prepare_subsample_index_array() -> np.ndarray:\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def resize_samplesizes() -> np.array:\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def decorrelate_collective_variables() -> np.ndarray:\n",
    "        pass\n",
    "\n",
    "@dataclass\n",
    "class DecorrelationBSE(DecorrelationEngine):\n",
    "    ### Does this work upon init ?\n",
    "    # def __post_init__(self, safetyFactor=2.0, minSamplesize=1000):\n",
    "    safetyFactor: float\n",
    "    minSamplesize: int\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.maxBlockSize: int = int(np.round(self.Hamiltonian_CVColumnsSamplesize / self.minSamplesize))\n",
    "        \n",
    "    def find_correlation_time(self) -> np.ndarray[float]:\n",
    "        \n",
    "        def logistic(x, a, k):\n",
    "            return a / (1. + np.exp(-k * (x - 1))) - 0.5 * a\n",
    "\n",
    "        def d2logistic_dx2(x, a, k):   # 2nd derivative of the logistic function above necessary for fitting a BSE curve\n",
    "            return -a * k**2 * (np.exp(k*(x-1)) - 1) * np.exp(k*(x-1)) / (np.exp(k*(x-1)) + 1)**3        \n",
    "        \n",
    "        ### there should be a loop through columns aswell\n",
    "        for i,_ in enumerate(self.Hamiltonian_CVColumnsSamplesize):\n",
    "            samplesize = self.Hamiltonian_CVColumnsSamplesize[i]\n",
    "            collectiveVariables = self.Hamiltonian_CollectiveVariable_Timeseries[i,:samplesize]\n",
    "            \n",
    "            BSE_List = []\n",
    "\n",
    "            for blockSize in range(1,self.maxBlockSize):\n",
    "                skip = samplesizes % blockSize   # to screen all integer blocksizes the first couple of CV sampes need to be excluded sometimes\n",
    "                blockedAverages = np.mean(collectiveVariables[skip:].reshape(-1, blockSize), axis=0)\n",
    "                blockedStandardError = np.std(blockedAverages)\n",
    "                BSE_List.append(blockedStandardError / np.sqrt(blockSize))\n",
    "\n",
    "            BSE = np.array(BSE_List)\n",
    "            blockSizes = np.arange(BSE.shape[0])\n",
    "\n",
    "            (logisticAmplitude, logisticGrowthRate), _ = opt.curve_fit(logistic, blockSizes, BSE)\n",
    "            BSE_fit = logistic(blockSizes,\n",
    "                               logisticAmplitude,\n",
    "                               logisticGrowthRate)\n",
    "\n",
    "            BSE_fit_2nd_derivative = d2logistic_dx2(blockSizes,\n",
    "                                                    logisticAmplitude,\n",
    "                                                    logisticGrowthRate)\n",
    "\n",
    "            correlationTimeEstimates.append(np.argsort(BSE_fit_2nd_derivative)[0])    # grossfield et al: t_corr = 2 * inflection_point; but whatever\n",
    "        self.correlationTime = np.array(correlationTimeEstimates * self.safetyFactor)\n",
    "        \n",
    "        return self.correlationTimeEstimate\n",
    "    \n",
    "    def prepare_subsample_index_array(self) -> None:\n",
    "        subsampleIndexList = []\n",
    "        for i,_ in eumerate(self.Hamiltonian_CVColumnsSamplesize):\n",
    "            indices = np.arange(self.Hamiltonian_CVColumnsSamplesize[i])\n",
    "            np.random.shuffle(indices)\n",
    "            decorrelatedSamplesize = int(self.Hamiltonian_CVColumnsSamplesize[i]/self.correlationTime[i])\n",
    "            indices[:decorrelatedSamplesize] = np.sort(indices[:decorrelatedSamplesize])\n",
    "            subsampleIndexList.append(indices)\n",
    "        self.subsampleIndexArray = np.array(subsampleIndexList)\n",
    "    \n",
    "    def resize_samplesizes(self) -> np.array:\n",
    "        for i,_ in enumerate(self.Hamiltonian_CVColumnsSamplesize):\n",
    "            self.Hamiltonian_CVColumnsSamplesize[i] = int(self.Hamiltonian_CVColumnsSamplesize[i]/self.correlationtime[i])\n",
    "        return self.Hamiltonian_CVColumnsSamplesize\n",
    "    \n",
    "    def decorrelate_collective_variables(self) -> np.ndarray:\n",
    "        for i,_ in enumerate(self.Hamiltonian_CollectiveVariable_Timeseries):\n",
    "            self.Hamiltonian_CollectiveVariable_Timeseries[i] = self.Hamiltonian_CollectiveVariable_Timeseries[i,self.subsampleIndexArray[i]]\n",
    "        return self.Hamiltonian_CollectiveVariable_Timeseries\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85525d47-c698-461c-a902-49e736465b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataContainer:\n",
    "    kB_kcalmolK: float = 0.001987204259\n",
    "    temperatureK: np.ndarray = np.array(300)\n",
    "    betaFactor: np.ndarray = 1 / (kB_kcalmolK*temperatureK)\n",
    "    \n",
    "    Anchors: np.ndarray = field(init=False)\n",
    "    ForceConstants: np.ndarray = field(init=False)\n",
    "    Hamiltonian_CollectiveVariable_Timeseries: list[np.ndarray] = field(init=False)\n",
    "    Hamiltonian_CVColumnsSamplesize: np.ndarray = field(init=False)\n",
    "    \n",
    "    def ParseData(self, file_parser: FileParser) -> None:\n",
    "        \n",
    "        def samplesizes_from_collective_variables():\n",
    "            samplesizes = [ts[ts!=0].shape[0] for CV_ts in self.Hamiltonian_CollectiveVariable_Timeseries for ts in CV_ts]\n",
    "            samplesizes = np.array(samplesizes).reshape(self.Hamiltonian_CollectiveVariable_Timeseries.shape[:-1])\n",
    "            return samplesizes\n",
    "        \n",
    "        self.Anchors = file_parser.parse_anchors()\n",
    "        self.ForceConstants = file_parser.parse_force_constants()\n",
    "        self.Hamiltonian_CollectiveVariable_Timeseries = file_parser.parse_collective_variables()\n",
    "        self.Hamiltonian_CVColumnsSamplesize = samplesizes_from_collective_variables()\n",
    "        \n",
    "    def DecorrelateData(self, decor_engine: DecorrelationEngine) -> None:\n",
    "        self.Hamiltonian_CollectiveVariable_Timeseries = DecorrelationEngine.decorrelate_collective_variables()\n",
    "        self.Hamiltonian_CVColumnsSamplesize = DecorrelationEngine.resize_samplesizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "050f2bd4-e0cf-419f-8c0d-ecf2438649b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "\n",
    "flattened = [element for row in matrix for element in row]\n",
    "\n",
    "print(flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e3d13f6-490a-4c11-807f-f3565834b5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_254005/4068384665.py:87: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  Hamiltonian_CollectiveVariable_Timeseries = np.column_stack((itertools.zip_longest(*CollectiveVariablesList, fillvalue=0)))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m dG_oS_DataContainer \u001b[38;5;241m=\u001b[39m DataContainer()\n\u001b[1;32m      7\u001b[0m dG_oS_DataContainer\u001b[38;5;241m.\u001b[39mParseData(parser)\n\u001b[0;32m----> 9\u001b[0m decorr_engine \u001b[38;5;241m=\u001b[39m \u001b[43mDecorrelationBSE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdG_oS_DataContainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHamiltonian_CVColumnsSamplesize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdG_oS_DataContainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHamiltonian_CollectiveVariable_Timeseries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m### Does this work upon init ?\u001b[39;00m\n\u001b[1;32m     13\u001b[0m dG_oS_DataContainer\u001b[38;5;241m.\u001b[39mDecorrelateData(decorr_engine)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# dG_oS_DataContainer.ParseData(AMBER_PMD_Parser)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# dG_oS_dataloader.decorrelate(decorrelationScheme())\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# dG_oS_Energy = FE_contribution('PMF-like')\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# if __name__ == '__main__':\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# main()\u001b[39;00m\n",
      "File \u001b[0;32m<string>:7\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, Hamiltonian_CollectiveVariable_Timeseries, Hamiltonian_CVColumnsSamplesize, safetyFactor, minSamplesize)\u001b[0m\n",
      "Cell \u001b[0;32mIn[4], line 33\u001b[0m, in \u001b[0;36mDecorrelationBSE.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__post_init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxBlockSize: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHamiltonian_CVColumnsSamplesize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminSamplesize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "files = natsorted(glob('../_sim/13*/_output/pmd_p*[!a].txt'))\n",
    "\n",
    "parser = AMBER_PMD_Parser(files, [5])\n",
    "\n",
    "dG_oS_DataContainer = DataContainer()\n",
    "dG_oS_DataContainer.ParseData(parser)\n",
    "\n",
    "decorr_engine = DecorrelationBSE(dG_oS_DataContainer.Hamiltonian_CVColumnsSamplesize,\n",
    "                                 dG_oS_DataContainer.Hamiltonian_CollectiveVariable_Timeseries,\n",
    "                                3,1000) ### Does this work upon init ?\n",
    "\n",
    "dG_oS_DataContainer.DecorrelateData(decorr_engine)\n",
    "\n",
    "    # dG_oS_DataContainer.ParseData(AMBER_PMD_Parser)\n",
    "    # dG_oS_dataloader.decorrelate(decorrelationScheme())\n",
    "    # dG_oS_Energy = FE_contribution('PMF-like')\n",
    "    \n",
    "# if __name__ == '__main__':\n",
    "    # main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wooroux]",
   "language": "python",
   "name": "conda-env-wooroux-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
